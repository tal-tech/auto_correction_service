{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nets import s3d as net\n",
    "from nets import ssd_common, np_methods\n",
    "from preprocessing import s3d_preprocessing, ssd_vgg_preprocessing\n",
    "from notebooks import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow session: grow memory when needed. TF, DO NOT USE ALL MY GPU MEMORY!!!\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "isess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SSD 300 Model\n",
    "\n",
    "The SSD 300 network takes 300x300 image inputs. In order to feed any image, the latter is resize to this input shape (i.e.`Resize.WARP_RESIZE`). Note that even though it may change the ratio width / height, the SSD model performs well on resized images (and it is the default behaviour in the original Caffe implementation).\n",
    "\n",
    "SSD anchors correspond to the default bounding boxes encoded in the network. The SSD net output provides offset on the coordinates and dimensions of these anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##### Input placeholder.\n",
    "net_shape = (512, 512)\n",
    "data_format = 'NHWC'\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "# Evaluation pre-processing: resize to SSD net shape.\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = s3d_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Define the SSD model.\n",
    "reuse = True if 'ssd_net' in locals() else None\n",
    "ssd_net = net.SSDNet()\n",
    "# SSD default anchor boxes.\n",
    "ssd_anchors = ssd_net.anchors(net_shape)\n",
    "with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n",
    "    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\n",
    "# model_path = '/workspace/OCR/models/train_models_s3d_3/checkpoint'\n",
    "# with open(model_path, 'r') as f:\n",
    "#     ckpts = f.readlines()\n",
    "# ckpt_filename = ckpts[-1].split(':')[1][2:-2]\n",
    "ckpt_filename = '/workspace/OCR/models/s3d/model.ckpt-30324'\n",
    "# Restore SSD model.\n",
    "# ckpt_filename = '../My_Model/model.ckpt-52918'\n",
    "# ckpt_filename = '/workspace/OCR/models/train_models_1class/model.ckpt-207004'\n",
    "# ckpt_filename = '/workspace/OCR/models/vgg/model.ckpt-229866'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Post-processing pipeline\n",
    "\n",
    "The SSD outputs need to be post-processed to provide proper detections. Namely, we follow these common steps:\n",
    "\n",
    "* Select boxes above a classification threshold;\n",
    "* Clip boxes to the image shape;\n",
    "* Apply the Non-Maximum-Selection algorithm: fuse together boxes whose Jaccard score > threshold;\n",
    "* If necessary, resize bounding boxes to original image shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_info = {\n",
    "    \"1\" : 'hs',\n",
    "    \"2\" : 'ss',\n",
    "    \"3\" : 'ts',\n",
    "    \"4\" : 'jfx'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_bboxes(img, classes, classes_info, scores, bboxes, figsize=(10,10), linewidth=1.5, save=False, name='demo.jpg'):\n",
    "    \"\"\"Visualize bounding boxes. Largely inspired by SSD-MXNET!\n",
    "    \"\"\"\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    if height < width:\n",
    "        cv2.resize(img,(512, int(width/height*512)))\n",
    "    else:\n",
    "        cv2.resize(img,(int(height/width*512), 512))\n",
    "    colors = {\n",
    "        1 : (255, 0, 0),\n",
    "        2 : (0, 255, 0),\n",
    "        3 : (0, 0, 255)\n",
    "    }\n",
    "    for i in range(classes.shape[0]):\n",
    "        cls_id = int(classes[i])\n",
    "        if cls_id >= 1:\n",
    "            score = scores[i]\n",
    "\n",
    "            ymin = int(bboxes[i, 0] * height)\n",
    "            xmin = int(bboxes[i, 1] * width)\n",
    "            ymax = int(bboxes[i, 2] * height)\n",
    "            xmax = int(bboxes[i, 3] * width)\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), colors[cls_id], 4)\n",
    "#             class_name = str(classes_info[str(cls_id)])\n",
    "#             s = '%s/%.3f' % (class_name, score)\n",
    "#             p1 = (xmin-5, ymin)\n",
    "#             cv2.putText(img, s, p1, cv2.FONT_HERSHEY_DUPLEX, 0.3, colors[cls_id], 1)\n",
    "    if save:\n",
    "        cv2.imwrite(name, img)\n",
    "    else:\n",
    "        plt.figure(figsize = (16, 16))\n",
    "        cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bboxes_area(bboxes):\n",
    "    h = bboxes[2] - bboxes[0]\n",
    "    w = bboxes[3] - bboxes[1]\n",
    "    return h*w\n",
    "\n",
    "def is_contain(box1, box2):\n",
    "    # if box1 is contained in box2\n",
    "    if (box1[0] > box2[0] and box1[1] > box2[1] and box1[2] < box2[2] and box1[3] < box2[3]):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bboxes_sort(classes, scores, bboxes, top_k=400):\n",
    "    \"\"\"Sort bounding boxes by decreasing order and keep only the top_k\n",
    "    \"\"\"\n",
    "    # if priority_inside:\n",
    "    #     inside = (bboxes[:, 0] > margin) & (bboxes[:, 1] > margin) & \\\n",
    "    #         (bboxes[:, 2] < 1-margin) & (bboxes[:, 3] < 1-margin)\n",
    "    #     idxes = np.argsort(-scores)\n",
    "    #     inside = inside[idxes]\n",
    "    #     idxes = np.concatenate([idxes[inside], idxes[~inside]])\n",
    "    idxes = np.argsort(-scores)\n",
    "    classes = classes[idxes][:top_k]\n",
    "    scores = scores[idxes][:top_k]\n",
    "    bboxes = bboxes[idxes][:top_k]\n",
    "    keep_bboxes = np.ones(scores.shape, dtype=np.bool)\n",
    "    for i in range(scores.size):\n",
    "        if bboxes_area(bboxes[i]) > 0.4:\n",
    "            keep_bboxes[i] = False\n",
    "        if classes[i] ==1 and bboxes_area(bboxes[i]) > 0.2:\n",
    "            keep_bboxes[i] = False\n",
    "        elif classes[i] != 1 and scores[i] < 0.2:\n",
    "            keep_bboxes[i] = False\n",
    "    return classes[keep_bboxes], scores[keep_bboxes], bboxes[keep_bboxes]\n",
    "\n",
    "\n",
    "def bboxes_IOS(bboxes1, bboxes2):\n",
    "    \"\"\"Computing jaccard index between bboxes1 and bboxes2.\n",
    "    Note: bboxes1 and bboxes2 can be multi-dimensional, but should broacastable.\n",
    "    \"\"\"\n",
    "    bboxes1 = np.transpose(bboxes1)\n",
    "    bboxes2 = np.transpose(bboxes2)\n",
    "    # Intersection bbox and volume.\n",
    "    int_ymin = np.maximum(bboxes1[0], bboxes2[0])\n",
    "    int_xmin = np.maximum(bboxes1[1], bboxes2[1])\n",
    "    int_ymax = np.minimum(bboxes1[2], bboxes2[2])\n",
    "    int_xmax = np.minimum(bboxes1[3], bboxes2[3])\n",
    "\n",
    "    int_h = np.maximum(int_ymax - int_ymin, 0.)\n",
    "    int_w = np.maximum(int_xmax - int_xmin, 0.)\n",
    "    int_vol = int_h * int_w\n",
    "    # Union volume.\n",
    "    vol1 = (bboxes1[2] - bboxes1[0]) * (bboxes1[3] - bboxes1[1])\n",
    "    vol2 = (bboxes2[2] - bboxes2[0]) * (bboxes2[3] - bboxes2[1])\n",
    "    jaccard = int_vol / np.minimum(vol1, vol2)\n",
    "    return jaccard\n",
    "\n",
    "def bboxes_nms(classes, scores, bboxes, nms_threshold=0.45):\n",
    "    \"\"\"Apply non-maximum selection to bounding boxes.\n",
    "    \"\"\"\n",
    "    keep_bboxes = np.ones(scores.shape, dtype=np.bool)\n",
    "    for i in range(scores.size-1):\n",
    "        if keep_bboxes[i]:\n",
    "            if classes[i] == 1:\n",
    "                # Computer overlap with bboxes which are following.\n",
    "                overlap = bboxes_IOS(bboxes[i], bboxes[(i+1):])\n",
    "                # Overlap threshold for keeping + checking part of the same class\n",
    "\n",
    "                keep_overlap = np.logical_or(overlap < nms_threshold, classes[(i+1):] != classes[i])\n",
    "                keep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):], keep_overlap)\n",
    "    #             keep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):], overlap < nms_threshold)\n",
    "            else:\n",
    "                overlap = bboxes_IOS(bboxes[i], bboxes[(i+1):])\n",
    "                keep_overlap = np.logical_or(overlap < (nms_threshold / 2), classes[(i+1):] == 1)\n",
    "                keep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):], keep_overlap)\n",
    "            \n",
    "\n",
    "    idxes = np.where(keep_bboxes)\n",
    "    return classes[idxes], scores[idxes], bboxes[idxes]\n",
    "\n",
    "def bboxes_filter(classes, scores, bboxes):\n",
    "    keep_bboxes = np.ones(scores.shape, dtype=np.bool)\n",
    "    for i in range(scores.size):\n",
    "        if classes[i] != 1:\n",
    "            for j in range(i):\n",
    "                if classes[j] != 1 and keep_bboxes[j]:\n",
    "                    ios = IOS_calculation(bboxes[i], bboxes[j])\n",
    "                    if ios > 0.9:\n",
    "                        keep_bboxes[i] = False\n",
    "    return classes[keep_bboxes], scores[keep_bboxes], bboxes[keep_bboxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##### Main image processing routine.\n",
    "def process_image(img, select_threshold=0.1, nms_threshold=.45, net_shape=(512, 512)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    net_time = time.time()\n",
    "    # Get classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, ssd_anchors,\n",
    "            select_threshold=select_threshold, img_shape=net_shape, num_classes=4\n",
    "        , decode=True)\n",
    "    \n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "#     print(rbboxes.shape)\n",
    "#     print(rclasses, rscores)\n",
    "    rclasses, rscores, rbboxes = bboxes_sort(rclasses, rscores, rbboxes, top_k=-1)\n",
    "#     print(rclasses, rscores)\n",
    "#     print(rclasses.shape, rscores.shape, rbboxes.shape)\n",
    "    rclasses, rscores, rbboxes = bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "#     rclasses, rscores, rbboxes = bboxes_filter(rclasses, rscores, rbboxes)\n",
    "#     print(rclasses.shape, rscores.shape, rbboxes.shape)\n",
    "    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "    nms_time = time.time()\n",
    "    return rclasses, rscores, rbboxes, net_time, nms_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test on some demo image and visualize output.\n",
    "path = '../../datasets/TAL_OCR/190326_4122/test/'\n",
    "# path = '../../datasets/TAL_OCR/xcs_highgrade/'\n",
    "# path = '../../datasets/TAL_OCR/190423_5594/imgs/'\n",
    "# path = './'\n",
    "# path = '../../datasets/TAL_OCR/badcase_img/'\n",
    "# path = '../../datasets/TAL_OCR/xc_test_imgs/'\n",
    "image_names = sorted(os.listdir(path))\n",
    "# print(image_names)s.size):0\n",
    "#         if bboxes_area(bboxes[i]) > 0.3:\n",
    "#             keep_bboxes["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(image_names)\n",
    "total_num = 10\n",
    "for i in tqdm(range(total_num)):\n",
    "#     image_names[i] = '3.jpg'\n",
    "#     print(image_names[i])\n",
    "    try:\n",
    "        img = cv2.imread(path + image_names[i])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    except:\n",
    "        print(image_names[i])\n",
    "        continue\n",
    "    rclasses, rscores, rbboxes, net_time, nms_time =  process_image(img)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "#     if height < width:\n",
    "#         img = cv2.resize(img,(int(width/height*512), 512))\n",
    "#     else:\n",
    "#         img = cv2.resize(img,(512, int(height/width*512)))\n",
    "    plt_bboxes(img, rclasses, class_info, rscores, rbboxes, \n",
    "                    save = False, name = '/workspace/OCR/datasets/TAL_OCR/pa_result/' + str(i) + '.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.92/0.92"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
